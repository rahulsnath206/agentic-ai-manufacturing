{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic AI Manufacturing Data Integration Prototype\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates an AI-powered solution for integrating manufacturing data silos (ERP + CMM) using intelligent schema mapping and comprehensive analytics.\n",
    "\n",
    "### Key Components:\n",
    "1. **Data Loading & Analysis** - Load and examine manufacturing datasets\n",
    "2. **AI Schema Mapping** - Use ML techniques to map schema relationships\n",
    "3. **Data Integration** - Create unified dataset from disparate sources\n",
    "4. **Quality Analytics** - Generate comprehensive quality metrics\n",
    "5. **Anomaly Detection** - Identify outliers and problematic patterns\n",
    "6. **Traceability Analysis** - Link defects to production lots\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our custom data processor\n",
    "from data_processor import DataProcessor\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"üìÖ Analysis started at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize the AI Agent and Load Data\n",
    "\n",
    "Our AI agent will intelligently process and integrate the manufacturing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the AI-powered data processor\n",
    "processor = DataProcessor()\n",
    "print(\"ü§ñ AI Agent initialized!\")\n",
    "\n",
    "# Load manufacturing data\n",
    "print(\"\\nüìÇ Loading manufacturing data...\")\n",
    "success = processor.load_data('production_data.csv', 'cmm_data.csv')\n",
    "\n",
    "if success:\n",
    "    print(\"‚úÖ Data loading completed successfully!\")\n",
    "    \n",
    "    # Display basic data information\n",
    "    print(f\"\\nüìä Production Data Shape: {processor.production_data.shape}\")\n",
    "    print(f\"üîç CMM Data Shape: {processor.cmm_data.shape}\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to load data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Examine Data Structure\n",
    "\n",
    "Let's examine the structure of both datasets to understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze data structure\n",
    "analysis = processor.analyze_data_structure()\n",
    "\n",
    "print(\"üè≠ PRODUCTION DATA ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {analysis['production_data']['shape']}\")\n",
    "print(f\"Columns: {analysis['production_data']['columns']}\")\n",
    "\n",
    "print(\"\\nüî¨ CMM DATA ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {analysis['cmm_data']['shape']}\")\n",
    "print(f\"Columns: {analysis['cmm_data']['columns']}\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nüìã PRODUCTION DATA SAMPLE:\")\n",
    "display(processor.production_data.head(3))\n",
    "\n",
    "print(\"\\nüß™ CMM DATA SAMPLE:\")\n",
    "display(processor.cmm_data.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: AI-Powered Schema Mapping\n",
    "\n",
    "This is the core AI functionality - the system will automatically figure out how to map columns between the two datasets using semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform AI-powered schema mapping\n",
    "print(\"üß† AI Agent performing schema mapping...\")\n",
    "print(\"This simulates what an LLM would do - finding semantic relationships!\\n\")\n",
    "\n",
    "mapping = processor.ai_powered_schema_mapping()\n",
    "\n",
    "print(\"üéØ DISCOVERED SCHEMA MAPPINGS:\")\n",
    "print(\"=\" * 40)\n",
    "for prod_col, cmm_col in mapping.items():\n",
    "    print(f\"üìä {prod_col:<20} ‚Üî {cmm_col}\")\n",
    "\n",
    "print(f\"\\n‚ú® AI successfully mapped {len(mapping)} column relationships!\")\n",
    "\n",
    "# Visualize the mapping\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=go.Sankey(\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 20,\n",
    "      line = dict(color = \"black\", width = 0.5),\n",
    "      label = list(mapping.keys()) + list(mapping.values()),\n",
    "      color = \"blue\"\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = list(range(len(mapping))),\n",
    "      target = [len(mapping) + i for i in range(len(mapping))],\n",
    "      value = [1] * len(mapping)\n",
    "  )))\n",
    "\n",
    "fig.update_layout(title_text=\"AI-Discovered Schema Mappings\", font_size=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Unified Dataset\n",
    "\n",
    "Now we'll integrate the two data sources into a single, unified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unified dataset\n",
    "print(\"üîó Creating unified dataset...\")\n",
    "unified_data = processor.create_unified_dataset()\n",
    "\n",
    "print(f\"‚úÖ Unified dataset created with {len(unified_data)} records!\")\n",
    "print(f\"üìä Original production records: {len(processor.production_data)}\")\n",
    "print(f\"üîç Original CMM records: {len(processor.cmm_data)}\")\n",
    "print(f\"üîó Unified records: {len(unified_data)}\")\n",
    "\n",
    "integration_rate = (len(unified_data) / max(len(processor.production_data), len(processor.cmm_data))) * 100\n",
    "print(f\"üìà Integration success rate: {integration_rate:.1f}%\")\n",
    "\n",
    "# Display sample of unified data\n",
    "print(\"\\nüéØ UNIFIED DATASET SAMPLE:\")\n",
    "display(unified_data[['lot_id', 'part_id', 'machine_id', 'feature_name', 'measured_value', 'result']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Quality Analytics Dashboard\n",
    "\n",
    "Generate comprehensive quality metrics and analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate comprehensive quality metrics\n",
    "print(\"üìä Calculating quality metrics...\")\n",
    "metrics = processor.calculate_quality_metrics()\n",
    "\n",
    "# Display overall quality metrics\n",
    "overall = metrics['overall_quality']\n",
    "print(f\"\\nüèÜ OVERALL QUALITY PERFORMANCE\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"‚úÖ Pass Rate: {overall['pass_rate_percent']}%\")\n",
    "print(f\"‚ùå Fail Rate: {overall['fail_rate_percent']}%\")\n",
    "print(f\"üß™ Total Tests: {overall['total_measurements']:,}\")\n",
    "print(f\"‚úÖ Passed: {overall['passed_measurements']:,}\")\n",
    "print(f\"‚ùå Failed: {overall['failed_measurements']:,}\")\n",
    "\n",
    "# Defect traceability\n",
    "traceability = metrics['defect_traceability']\n",
    "print(f\"\\nüîç DEFECT TRACEABILITY\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üì¶ Total Production Lots: {traceability['total_lots']:,}\")\n",
    "print(f\"‚ö†Ô∏è Lots with Defects: {traceability['lots_with_defects']:,}\")\n",
    "defect_lot_rate = (traceability['lots_with_defects'] / traceability['total_lots']) * 100\n",
    "print(f\"üìä Defective Lot Rate: {defect_lot_rate:.1f}%\")\n",
    "\n",
    "# Create quality visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Quality Analytics Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Pass/Fail Rate Pie Chart\n",
    "labels = ['Pass', 'Fail']\n",
    "sizes = [overall['passed_measurements'], overall['failed_measurements']]\n",
    "colors = ['#28a745', '#dc3545']\n",
    "axes[0,0].pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "axes[0,0].set_title('Overall Pass/Fail Rate')\n",
    "\n",
    "# 2. Quality by Machine\n",
    "machine_quality = metrics['quality_by_machine']\n",
    "machines = list(machine_quality.keys())[:10]  # Top 10 machines\n",
    "quality_rates = [machine_quality[m] for m in machines]\n",
    "bars = axes[0,1].bar(machines, quality_rates, color='skyblue')\n",
    "axes[0,1].set_title('Quality Rate by Machine (Top 10)')\n",
    "axes[0,1].set_ylabel('Pass Rate (%)')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add color coding for bars\n",
    "for i, bar in enumerate(bars):\n",
    "    if quality_rates[i] >= 95:\n",
    "        bar.set_color('#28a745')  # Green for good\n",
    "    elif quality_rates[i] >= 90:\n",
    "        bar.set_color('#ffc107')  # Yellow for warning\n",
    "    else:\n",
    "        bar.set_color('#dc3545')  # Red for poor\n",
    "\n",
    "# 3. Quality by Shift\n",
    "shift_quality = metrics['quality_by_shift']\n",
    "shift_names = {1: 'Morning', 2: 'Afternoon', 3: 'Night'}\n",
    "shifts = [shift_names.get(k, f'Shift {k}') for k in shift_quality.keys()]\n",
    "shift_rates = list(shift_quality.values())\n",
    "axes[1,0].bar(shifts, shift_rates, color=['#ff9999', '#66b3ff', '#99ff99'])\n",
    "axes[1,0].set_title('Quality Rate by Shift')\n",
    "axes[1,0].set_ylabel('Pass Rate (%)')\n",
    "\n",
    "# 4. Quality by Plant\n",
    "plant_quality = metrics['quality_by_plant']\n",
    "plants = list(plant_quality.keys())\n",
    "plant_rates = list(plant_quality.values())\n",
    "axes[1,1].bar(plants, plant_rates, color=['#ffcc99', '#ff99cc', '#ccffcc'])\n",
    "axes[1,1].set_title('Quality Rate by Plant')\n",
    "axes[1,1].set_ylabel('Pass Rate (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà Quality analytics visualization completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Anomaly Detection\n",
    "\n",
    "Use statistical methods to detect anomalous measurements and patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform anomaly detection\n",
    "print(\"üö® Performing anomaly detection...\")\n",
    "anomalies = processor.detect_anomalies()\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è ANOMALY DETECTION RESULTS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üîç Total Measurements: {len(processor.unified_data):,}\")\n",
    "print(f\"üö® Anomalies Found: {anomalies['total_anomalies']:,}\")\n",
    "print(f\"üìä Anomaly Rate: {anomalies['anomaly_percentage']}%\")\n",
    "\n",
    "# Deviation statistics\n",
    "dev_stats = anomalies['deviation_statistics']\n",
    "print(f\"\\nüìè MEASUREMENT DEVIATION ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üìä Mean Deviation: {dev_stats['mean']:.4f}\")\n",
    "print(f\"üìà Std Deviation: {dev_stats['std']:.4f}\")\n",
    "print(f\"üìâ Q1 (25th percentile): {dev_stats['q1']:.4f}\")\n",
    "print(f\"üìà Q3 (75th percentile): {dev_stats['q3']:.4f}\")\n",
    "print(f\"üìä IQR: {dev_stats['iqr']:.4f}\")\n",
    "\n",
    "# Top anomalous measurements\n",
    "print(f\"\\nüéØ TOP 10 ANOMALOUS MEASUREMENTS\")\n",
    "print(\"=\" * 60)\n",
    "top_anomalies = anomalies['top_anomalous_measurements'][:10]\n",
    "for i, anomaly in enumerate(top_anomalies, 1):\n",
    "    print(f\"{i:2d}. Part: {anomaly['part_id']}, Lot: {anomaly['lot_id']}, \"\n",
    "          f\"Feature: {anomaly['feature_name']}, Deviation: {anomaly['deviation']:.4f}\")\n",
    "\n",
    "# Visualize anomalies\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Anomaly Detection Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Deviation Distribution\n",
    "deviations = processor.unified_data['deviation']\n",
    "axes[0,0].hist(deviations, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].axvline(dev_stats['mean'], color='red', linestyle='--', label=f'Mean: {dev_stats[\"mean\"]:.4f}')\n",
    "axes[0,0].set_title('Distribution of Measurement Deviations')\n",
    "axes[0,0].set_xlabel('Deviation from Nominal')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# 2. Anomalies by Machine\n",
    "anomaly_machine = anomalies['anomalies_by_machine']\n",
    "if anomaly_machine:\n",
    "    machines = list(anomaly_machine.keys())[:10]\n",
    "    counts = [anomaly_machine[m] for m in machines]\n",
    "    bars = axes[0,1].bar(machines, counts, color='red', alpha=0.7)\n",
    "    axes[0,1].set_title('Anomalies by Machine (Top 10)')\n",
    "    axes[0,1].set_ylabel('Number of Anomalies')\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Anomalies by Feature\n",
    "anomaly_feature = anomalies['anomalies_by_feature']\n",
    "if anomaly_feature:\n",
    "    features = list(anomaly_feature.keys())[:10]\n",
    "    counts = [anomaly_feature[f] for f in features]\n",
    "    axes[1,0].bar(features, counts, color='orange', alpha=0.7)\n",
    "    axes[1,0].set_title('Anomalies by Feature Type (Top 10)')\n",
    "    axes[1,0].set_ylabel('Number of Anomalies')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Scatter plot of deviations vs measurements\n",
    "sample_data = processor.unified_data.sample(1000)  # Sample for readability\n",
    "colors = ['red' if result == 'fail' else 'green' for result in sample_data['result']]\n",
    "axes[1,1].scatter(sample_data['measured_value'], sample_data['deviation'], \n",
    "                 c=colors, alpha=0.6, s=30)\n",
    "axes[1,1].set_title('Measured Value vs Deviation (Sample)')\n",
    "axes[1,1].set_xlabel('Measured Value')\n",
    "axes[1,1].set_ylabel('Deviation from Nominal')\n",
    "\n",
    "# Add legend for colors\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', markerfacecolor='g', markersize=10, label='Pass'),\n",
    "                   Line2D([0], [0], marker='o', color='w', markerfacecolor='r', markersize=10, label='Fail')]\n",
    "axes[1,1].legend(handles=legend_elements)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Anomaly detection analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Comprehensive Analysis Report\n",
    "\n",
    "Generate a complete analysis report with all findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive analysis report\n",
    "print(\"üìã Generating comprehensive analysis report...\")\n",
    "report = processor.generate_analysis_report()\n",
    "\n",
    "print(f\"\\nüìä MANUFACTURING DATA INTEGRATION REPORT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"‚è∞ Generated: {report['timestamp']}\")\n",
    "\n",
    "# Data summary\n",
    "data_summary = report['data_summary']\n",
    "print(f\"\\nüìÇ DATA INTEGRATION SUMMARY\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"üì¶ Production Records: {data_summary['production_records']:,}\")\n",
    "print(f\"üîç CMM Measurements: {data_summary['cmm_measurements']:,}\")\n",
    "print(f\"üîó Unified Records: {data_summary['unified_records']:,}\")\n",
    "print(f\"üß† AI Schema Mappings: {len(data_summary['schema_mapping'])}\")\n",
    "\n",
    "# Quality summary\n",
    "quality = report['quality_metrics']['overall_quality']\n",
    "print(f\"\\nüèÜ QUALITY PERFORMANCE SUMMARY\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"‚úÖ Overall Pass Rate: {quality['pass_rate_percent']}%\")\n",
    "print(f\"‚ùå Overall Fail Rate: {quality['fail_rate_percent']}%\")\n",
    "print(f\"üß™ Total Quality Tests: {quality['total_measurements']:,}\")\n",
    "\n",
    "# Anomaly summary\n",
    "anomaly_summary = report['anomaly_detection']\n",
    "print(f\"\\nüö® ANOMALY DETECTION SUMMARY\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"‚ö†Ô∏è Total Anomalies: {anomaly_summary['total_anomalies']:,}\")\n",
    "print(f\"üìä Anomaly Rate: {anomaly_summary['anomaly_percentage']}%\")\n",
    "print(f\"üìè Mean Deviation: {anomaly_summary['deviation_statistics']['mean']:.4f}\")\n",
    "\n",
    "# Key insights\n",
    "print(f\"\\nüí° KEY INSIGHTS & RECOMMENDATIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Identify worst performing machines\n",
    "machine_quality = report['quality_metrics']['quality_by_machine']\n",
    "worst_machines = sorted(machine_quality.items(), key=lambda x: x[1])[:3]\n",
    "print(f\"üè≠ Machines needing attention:\")\n",
    "for machine, quality_rate in worst_machines:\n",
    "    print(f\"   ‚Ä¢ {machine}: {quality_rate:.1f}% pass rate\")\n",
    "\n",
    "# Identify problematic shifts\n",
    "shift_quality = report['quality_metrics']['quality_by_shift']\n",
    "shift_names = {1: 'Morning', 2: 'Afternoon', 3: 'Night'}\n",
    "worst_shift = min(shift_quality.items(), key=lambda x: x[1])\n",
    "print(f\"\\n‚è∞ Shift performance:\")\n",
    "print(f\"   ‚Ä¢ {shift_names.get(worst_shift[0], f'Shift {worst_shift[0]}')} shift has lowest quality: {worst_shift[1]:.1f}%\")\n",
    "\n",
    "# Top anomalous features\n",
    "feature_anomalies = anomaly_summary['anomalies_by_feature']\n",
    "if feature_anomalies:\n",
    "    worst_features = sorted(feature_anomalies.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    print(f\"\\nüîç Features with most anomalies:\")\n",
    "    for feature, count in worst_features:\n",
    "        print(f\"   ‚Ä¢ {feature}: {count} anomalies\")\n",
    "\n",
    "print(f\"\\n‚úÖ Analysis report generation completed!\")\n",
    "print(f\"üìÑ Report contains {len(str(report))} characters of detailed analysis data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Export Results and Create Deliverables\n",
    "\n",
    "Export the unified dataset and analysis results for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export unified dataset\n",
    "print(\"üì§ Exporting analysis results...\")\n",
    "\n",
    "# 1. Export unified dataset\n",
    "unified_filename = f\"unified_manufacturing_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "processor.unified_data.to_csv(unified_filename, index=False)\n",
    "print(f\"‚úÖ Unified dataset exported: {unified_filename}\")\n",
    "\n",
    "# 2. Export analysis report as JSON\n",
    "import json\n",
    "report_filename = f\"manufacturing_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(report_filename, 'w') as f:\n",
    "    json.dump(report, f, indent=2, default=str)\n",
    "print(f\"‚úÖ Analysis report exported: {report_filename}\")\n",
    "\n",
    "# 3. Export defects-only dataset for targeted analysis\n",
    "defects_data = processor.unified_data[processor.unified_data['result'] == 'fail']\n",
    "defects_filename = f\"defects_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "defects_data.to_csv(defects_filename, index=False)\n",
    "print(f\"‚úÖ Defects dataset exported: {defects_filename}\")\n",
    "\n",
    "# Display final statistics\n",
    "print(f\"\\nüìä FINAL EXPORT SUMMARY\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üìÅ Files created: 3\")\n",
    "print(f\"üîó Unified records: {len(processor.unified_data):,}\")\n",
    "print(f\"‚ö†Ô∏è Defect records: {len(defects_data):,}\")\n",
    "print(f\"üìã Analysis data points: {len(str(report))}\")\n",
    "\n",
    "print(f\"\\nüéâ AGENTIC AI MANUFACTURING INTEGRATION PROTOTYPE COMPLETED!\")\n",
    "print(f\"‚è±Ô∏è Total analysis time: {datetime.now()}\")\n",
    "print(f\"‚ú® Ready for production deployment and stakeholder presentation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What We've Accomplished:\n",
    "\n",
    "1. **‚úÖ Data Integration**: Successfully integrated ERP production data with CMM quality measurements\n",
    "2. **üß† AI Schema Mapping**: Implemented intelligent schema mapping using semantic similarity\n",
    "3. **üìä Quality Analytics**: Generated comprehensive quality metrics and KPIs\n",
    "4. **üö® Anomaly Detection**: Identified outliers and problematic patterns in measurements\n",
    "5. **üîç Traceability**: Established clear links between production lots and quality issues\n",
    "6. **üì§ Export Capabilities**: Created exportable datasets and reports\n",
    "\n",
    "### Key Technical Innovations:\n",
    "\n",
    "- **Agentic AI Approach**: System makes autonomous decisions about data relationships\n",
    "- **Semantic Schema Mapping**: Uses TF-IDF and cosine similarity to find column relationships\n",
    "- **Statistical Anomaly Detection**: Employs IQR method for outlier identification\n",
    "- **Comprehensive Analytics**: Multi-dimensional quality analysis across machines, shifts, plants\n",
    "\n",
    "### Business Value:\n",
    "\n",
    "- **Improved Quality Control**: Real-time identification of quality issues\n",
    "- **Root Cause Analysis**: Clear traceability from defects to production parameters\n",
    "- **Operational Intelligence**: Data-driven insights for manufacturing optimization\n",
    "- **Reduced Manual Effort**: Automated integration eliminates manual data correlation\n",
    "\n",
    "### Ready for Production:\n",
    "\n",
    "This prototype demonstrates enterprise-ready capabilities and can be extended with:\n",
    "- Real-time data streaming\n",
    "- Advanced ML models for predictive quality\n",
    "- Integration with existing manufacturing systems\n",
    "- Automated alerting and notification systems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
